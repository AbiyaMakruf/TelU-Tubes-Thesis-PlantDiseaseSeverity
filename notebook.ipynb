{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42aadcc9",
   "metadata": {},
   "source": [
    "# Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b155fc2",
   "metadata": {},
   "source": [
    "## Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685e7c1",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.data.annotator import auto_annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf4078",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Object Detection\n",
    "rf = Roboflow(api_key=\"m1DZYxXInBZk9zMy3jDT\")\n",
    "project = rf.workspace(\"abiya\").project(\"plant-pathology-anotation\")\n",
    "version = project.version(7)\n",
    "dataset = version.download(\"yolov11\", location=\"dataset/objectDetection/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d926bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Mask Lesi\n",
    "rf = Roboflow(api_key=\"m1DZYxXInBZk9zMy3jDT\")\n",
    "project = rf.workspace(\"abiya\").project(\"plant-pathology-anotation\")\n",
    "version = project.version(10)\n",
    "dataset = version.download(\"yolov11\", location=\"dataset/maskLesi/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e227e48",
   "metadata": {},
   "source": [
    "## Variabel Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf683ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabel Global\n",
    "epochs = 100\n",
    "imgsz = 640\n",
    "model_variants_objectDetection = ['n', 's', 'm']\n",
    "model_variants_maskDaun = ['n', 's', 'm']\n",
    "model_variants_maskLesi = ['n', 's', 'm']\n",
    "# ['n', 's', 'm', 'l']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed257141",
   "metadata": {},
   "source": [
    "## Training Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3380c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "dataset_objectDetection = \"dataset/objectDetection/data.yaml\"\n",
    "output_csv_objectDetection = \"results/objectDetection/csv/\"\n",
    "output_runs_objectDetection = \"results/objectDetection/runs/\"\n",
    "output_plot_objectDetection = \"results/objectDetection/plot/\"\n",
    "\n",
    "# Memastikan folder output ada\n",
    "os.makedirs(output_csv_objectDetection, exist_ok=True)\n",
    "os.makedirs(output_runs_objectDetection, exist_ok=True)\n",
    "os.makedirs(output_plot_objectDetection, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi file ringkasan\n",
    "summary_train_file = os.path.join(output_csv_objectDetection, \"final_train_summary.csv\")\n",
    "summary_val_file = os.path.join(output_csv_objectDetection, \"final_val_summary.csv\")\n",
    "\n",
    "# Header ringkasan\n",
    "train_header = [\n",
    "    \"variant\", \"train_time_h\", \"train_time_m\", \"train_time_s\"\n",
    "]\n",
    "val_header = [\n",
    "    \"variant\", \"precision\", \"recall\", \"mAP50\", \"mAP50-95\",\n",
    "]\n",
    "\n",
    "# Inisialisasi file ringkasan\n",
    "with open(summary_train_file, mode=\"w\", newline=\"\") as f_train, \\\n",
    "     open(summary_val_file, mode=\"w\", newline=\"\") as f_val:\n",
    "    csv.writer(f_train).writerow(train_header)\n",
    "    csv.writer(f_val).writerow(val_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a199ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop tiap varian model\n",
    "for variant in model_variants_objectDetection:\n",
    "    model_name = f\"yolo11{variant}.pt\"\n",
    "    train_name = f\"train_{variant}\"\n",
    "    project_path = f\"{output_runs_objectDetection}detect/{train_name}\"\n",
    "    model = YOLO(model_name)\n",
    "\n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    results = model.train(\n",
    "        data=dataset_objectDetection,\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        project=f\"{output_runs_objectDetection}/detect\",\n",
    "        name=train_name,\n",
    "        verbose=False\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Simpan waktu training\n",
    "    elapsed = end_time - start_time\n",
    "    hours = int(elapsed // 3600)\n",
    "    minutes = int((elapsed % 3600) // 60)\n",
    "    seconds = int(elapsed % 60)\n",
    "\n",
    "    # Simpan ke summary_train_file\n",
    "    with open(summary_train_file, mode=\"a\", newline=\"\") as f_train:\n",
    "        csv.writer(f_train).writerow([variant, hours, minutes, seconds])\n",
    "\n",
    "    # === Simpan log setiap epoch ===\n",
    "    results_csv_path = os.path.join(project_path, \"results.csv\")\n",
    "    if os.path.exists(results_csv_path):\n",
    "        df = pd.read_csv(results_csv_path)\n",
    "        df.to_csv(os.path.join(output_csv_objectDetection, f\"train_logs_{variant}.csv\"), index=False)\n",
    "\n",
    "    # === Evaluasi / Validasi ===\n",
    "    best_model_path = os.path.join(project_path, \"weights\", \"best.pt\")\n",
    "    model = YOLO(best_model_path)\n",
    "    val_name = f\"val_{variant}\"\n",
    "    metrics = model.val(\n",
    "        data=dataset_objectDetection,\n",
    "        imgsz=imgsz,\n",
    "        split='test',\n",
    "        project=f\"{output_runs_objectDetection}/detect\",\n",
    "        name=val_name,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Simpan ke summary_val_file\n",
    "    with open(summary_val_file, mode=\"a\", newline=\"\") as f_val:\n",
    "        writer = csv.writer(f_val)\n",
    "        results_dict = metrics.results_dict\n",
    "        writer.writerow([\n",
    "            variant,\n",
    "            round(results_dict['metrics/precision(B)'], 4),\n",
    "            round(results_dict['metrics/recall(B)'], 4),\n",
    "            round(results_dict['metrics/mAP50(B)'], 4),\n",
    "            round(results_dict['metrics/mAP50-95(B)'], 4),\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perbandingan Metrik antar Varian\n",
    "metrics = {\n",
    "    \"metrics/mAP50(B)\": \"mAP@0.5\",\n",
    "    \"metrics/mAP50-95(B)\": \"mAP@0.5-0.95\",\n",
    "    \"time\": \"time\",\n",
    "}\n",
    "\n",
    "# Buat dictionary file\n",
    "files = {v: os.path.join(output_csv_objectDetection, f\"train_logs_{v}.csv\") for v in model_variants_objectDetection}\n",
    "\n",
    "# Loop setiap metrik dan buat plot perbandingan\n",
    "for metric_col, metric_label in metrics.items():\n",
    "    plt.figure()\n",
    "    for variant, file_path in files.items():\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            if metric_col in df.columns:\n",
    "                plt.plot(df[\"epoch\"], df[metric_col], label=f\"YOLOv11-{variant}\")\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric_label)\n",
    "    plt.title(f\"Perbandingan {metric_label} antar Varian\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    safe_name = metric_col.replace(\"/\", \"_\")\n",
    "    plt.savefig(os.path.join(output_plot_objectDetection, f\"compare_{safe_name}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12cf94",
   "metadata": {},
   "source": [
    "## Training Mask Daun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabel Global\n",
    "output_runs_maskDaun = \"results/maskDaun/runs/\"\n",
    "output_csv_maskDaun = \"results/maskDaun/csv/\"\n",
    "output_plot_maskDaun = \"results/maskDaun/plot/\"\n",
    "original_dataset = \"dataset/objectDetection\"\n",
    "maskDaun_dataset = \"dataset/maskDaun\"\n",
    "sam2_model = \"sam2_b.pt\"\n",
    "best_model_path = \"results/objectDetection/runs/detect/train_m/weights/best.pt\"\n",
    "\n",
    "# Memastikan folder output ada\n",
    "os.makedirs(output_runs_maskDaun, exist_ok=True)\n",
    "os.makedirs(output_csv_maskDaun, exist_ok=True)\n",
    "os.makedirs(output_plot_maskDaun, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac09570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Folder Dataset\n",
    "shutil.copytree(src=original_dataset, dst=maskDaun_dataset, dirs_exist_ok=True)\n",
    "\n",
    "# Hapus folder labels pada train, valid, test\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "for split in splits:\n",
    "    label_path = os.path.join(maskDaun_dataset, split, \"labels\")\n",
    "    if os.path.exists(label_path):\n",
    "        shutil.rmtree(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bbc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto Annotate\n",
    "\n",
    "# train\n",
    "auto_annotate(data=f\"{maskDaun_dataset}/train/images/\", det_model=best_model_path, sam_model=sam2_model, output_dir=f\"{maskDaun_dataset}/train/labels/\")\n",
    "\n",
    "# valid\n",
    "auto_annotate(data=f\"{maskDaun_dataset}/valid/images/\", det_model=best_model_path, sam_model=sam2_model, output_dir=f\"{maskDaun_dataset}/valid/labels/\")\n",
    "\n",
    "# test\n",
    "auto_annotate(data=f\"{maskDaun_dataset}/test/images/\", det_model=best_model_path, sam_model=sam2_model, output_dir=f\"{maskDaun_dataset}/test/labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== File CSV Ringkasan Evaluasi =====\n",
    "summary_csv = os.path.join(output_csv_maskDaun, \"summary_segmentation_metrics.csv\")\n",
    "with open(summary_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"variant\", \"mAP_box\", \"mAP_mask\"])\n",
    "\n",
    "# ===== Loop Training dan Validasi =====\n",
    "for variant in model_variants_maskDaun:\n",
    "    model_name = f\"yolo11{variant}-seg.pt\"\n",
    "    run_name = f\"train_maskDaun_{variant}\"\n",
    "    project_dir = os.path.join(output_runs_maskDaun, run_name)\n",
    "\n",
    "    # Load dan latih model\n",
    "    model = YOLO(model_name)\n",
    "    results = model.train(\n",
    "        data=f\"{maskDaun_dataset}/data.yaml\",\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        project=output_runs_maskDaun,\n",
    "        name=run_name,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Simpan CSV log training per epoch\n",
    "    results_csv = os.path.join(project_dir, \"results.csv\")\n",
    "    if os.path.exists(results_csv):\n",
    "        df = pd.read_csv(results_csv)\n",
    "        df.to_csv(os.path.join(output_csv_maskDaun, f\"train_logs_seg_{variant}.csv\"), index=False)\n",
    "\n",
    "    # Validasi terhadap split test\n",
    "    best_model_path = os.path.join(project_dir, \"weights\", \"best.pt\")\n",
    "    model = YOLO(best_model_path)\n",
    "    val_name = f\"val_maskDaun_{variant}\"\n",
    "    metrics = model.val(\n",
    "        data=f\"{maskDaun_dataset}/data.yaml\",\n",
    "        imgsz=imgsz,\n",
    "        split='test',\n",
    "        project=output_runs_maskDaun,\n",
    "        name=val_name,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Simpan mAP ke summary CSV\n",
    "    results_dict = metrics.results_dict\n",
    "    with open(summary_csv, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            variant,\n",
    "            round(results_dict['metrics/mAP50(B)'], 4),\n",
    "            round(results_dict['metrics/mAP50(M)'], 4)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_labels = {\n",
    "    \"metrics/mAP50(B)\": \"mAP@0.5\",\n",
    "    \"metrics/mAP50-95(B)\": \"mAP@0.5-0.95\",\n",
    "    \"metrics/mAP50(M)\": \"mAP@0.5-0.95\",\n",
    "    \"metrics/mAP50-95(M)\": \"mAP@0.5-0.95\",\n",
    "    \"time\": \"time\",\n",
    "}\n",
    "\n",
    "# === Plot log per epoch ===\n",
    "for metric_col, label in metric_labels.items():\n",
    "    plt.figure()\n",
    "    for v in model_variants_maskDaun:\n",
    "        file_path = os.path.join(output_csv_maskDaun, f\"train_logs_seg_{v}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            if metric_col in df.columns:\n",
    "                plt.plot(df[\"epoch\"], df[metric_col], label=f\"YOLOv11-{v}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(label)\n",
    "    plt.title(f\"Perbandingan {label} antar Varian (Segmentation)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    safe_name = metric_col.replace(\"/\", \"_\")\n",
    "    plt.savefig(os.path.join(output_plot_maskDaun, f\"compare_seg_{safe_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# === Plot summary mAP Box dan mAP Mask ===\n",
    "summary_file = os.path.join(output_csv_maskDaun, \"summary_segmentation_metrics.csv\")\n",
    "if os.path.exists(summary_file):\n",
    "    df = pd.read_csv(summary_file)\n",
    "    for col, label in zip([\"mAP_box\", \"mAP_mask\"], [\"mAP Box\", \"mAP Mask\"]):\n",
    "        plt.figure()\n",
    "        plt.bar(df[\"variant\"], df[col])\n",
    "        plt.title(f\"{label} per Varian (Segmentasi)\")\n",
    "        plt.ylabel(label)\n",
    "        plt.xlabel(\"YOLOv8 Variant\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_plot_maskDaun, f\"summary_{col}.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d607f9",
   "metadata": {},
   "source": [
    "## Training Mask Lesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabel Global\n",
    "dataset_maskLesi = \"dataset/maskLesi/data.yaml\"\n",
    "output_csv_maskLesi = \"results/maskLesi/csv/\"\n",
    "output_runs_maskLesi = \"results/maskLesi/runs/\"\n",
    "output_plot_maskLesi = \"results/maskLesi/plot/\"\n",
    "\n",
    "# Buat folder jika belum ada\n",
    "os.makedirs(output_csv_maskLesi, exist_ok=True)\n",
    "os.makedirs(output_runs_maskLesi, exist_ok=True)\n",
    "os.makedirs(output_plot_maskLesi, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inisialisasi Summary CSV ===\n",
    "summary_csv = os.path.join(output_csv_maskLesi, \"summary_segmentation_metrics.csv\")\n",
    "with open(summary_csv, \"w\", newline=\"\") as f:\n",
    "    csv.writer(f).writerow([\"variant\", \"mAP_box\", \"mAP_mask\"])\n",
    "\n",
    "# === Training dan Validasi Loop ===\n",
    "for variant in model_variants_maskLesi:\n",
    "    model_path = f\"yolo11{variant}-seg.pt\"\n",
    "    run_name = f\"train_maskLesi_{variant}\"\n",
    "    run_path = os.path.join(output_runs_maskLesi, run_name)\n",
    "\n",
    "    # Load dan latih model\n",
    "    model = YOLO(model_path)\n",
    "    results = model.train(\n",
    "        data=dataset_maskLesi,\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        project=output_runs_maskLesi,\n",
    "        name=run_name,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Simpan log training per epoch\n",
    "    results_csv = os.path.join(run_path, \"results.csv\")\n",
    "    if os.path.exists(results_csv):\n",
    "        df = pd.read_csv(results_csv)\n",
    "        df.to_csv(os.path.join(output_csv_maskLesi, f\"train_logs_seg_{variant}.csv\"), index=False)\n",
    "\n",
    "    # Validasi dan ambil metrik\n",
    "    best_model_path = os.path.join(run_path, \"weights\", \"best.pt\")\n",
    "    model = YOLO(best_model_path)\n",
    "    metrics = model.val(\n",
    "        data=dataset_maskLesi, \n",
    "        imgsz=imgsz, \n",
    "        project=output_runs_maskLesi,\n",
    "        name=f\"val_maskLesi_{variant}\",\n",
    "        split='test', \n",
    "        verbose=False)\n",
    "    results_dict = metrics.results_dict\n",
    "\n",
    "    # Simpan ringkasan mAP\n",
    "    with open(summary_csv, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            variant,\n",
    "            round(results_dict['metrics/mAP50(B)'], 4),\n",
    "            round(results_dict['metrics/mAP50(M)'], 4)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualisasi Otomatis ===\n",
    "metric_labels = {\n",
    "    \"metrics/mAP50(B)\": \"mAP@0.5\",\n",
    "    \"metrics/mAP50-95(B)\": \"mAP@0.5-0.95\",\n",
    "    \"metrics/mAP50(M)\": \"mAP@0.5\",\n",
    "    \"metrics/mAP50-95(M)\": \"mAP@0.5-0.95\",\n",
    "    \"time\": \"time\",\n",
    "}\n",
    "\n",
    "# Plot log per epoch\n",
    "for metric_col, label in metric_labels.items():\n",
    "    plt.figure()\n",
    "    for variant in model_variants_maskLesi:\n",
    "        log_path = os.path.join(output_csv_maskLesi, f\"train_logs_seg_{variant}.csv\")\n",
    "        if os.path.exists(log_path):\n",
    "            df = pd.read_csv(log_path)\n",
    "            if metric_col in df.columns:\n",
    "                plt.plot(df[\"epoch\"], df[metric_col], label=f\"YOLOv11-{variant}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(label)\n",
    "    plt.title(f\"{label} per Epoch (Mask Lesi)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    safe_name = metric_col.replace(\"/\", \"_\")\n",
    "    plt.savefig(os.path.join(output_plot_maskLesi, f\"compare_{safe_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Plot summary mAP\n",
    "summary_df = pd.read_csv(summary_csv)\n",
    "for col, label in zip([\"mAP_box\", \"mAP_mask\"], [\"mAP Box\", \"mAP Mask\"]):\n",
    "    plt.figure()\n",
    "    plt.bar(summary_df[\"variant\"], summary_df[col])\n",
    "    plt.title(f\"{label} per Varian (Mask Lesi)\")\n",
    "    plt.ylabel(label)\n",
    "    plt.xlabel(\"YOLOv8 Variant\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_plot_maskLesi, f\"summary_{col}.png\"))\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
